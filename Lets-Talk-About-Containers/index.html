<!doctype html>
<html lang="de">
  <head>
	<meta charset="utf-8">
	<title>FIXME(cglaubitz): INSERT TITLE HERE</title>
	<meta name="description" content="Containers then and now">
	<meta name="author" content="Christoph Glaubitz">
	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
	<link rel="stylesheet" href="../reveal.js-3.0.0/css/reveal.css">
	<link rel="stylesheet" href="../reveal.js-3.0.0/css/theme/syseleven.css" id="theme">
	<link rel="stylesheet" href="../reveal.js-3.0.0/lib/css/zenburn.css">
	<link rel="stylesheet" href="../font-awesome-4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="css/chris.css">
	<script>
		var link = document.createElement( 'link' );
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match( ../reveal.js-3.0.0/print-pdf/gi ) ? '../reveal.js-3.0.0/css/print/pdf.css' : '../reveal.js-3.0.0/css/print/paper.css';
		document.getElementsByTagName( 'head' )[0].appendChild( link );
	</script>
	<!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

<section data-markdown data-separator="^\n---\n$" data-separator-vertical="^\n--\n$">
<pre><code></code></pre>
<script type="text/template" >
<!-- .slide: class="left" data-background="../reveal.js-3.0.0/sys11-images/140212-SYS11-Presentor-Background-01-Title-02-90.png" -->

Containers then and now<!-- .element: style="font-size:150%;" -->

<aside class="author">
Christoph Glaubitz<br>
Cloud Architect at SysEleven GmbH<br>
<span class="location">ContainerDays Hamburg, 27 &amp; 28.06.2016</span>
</aside>

---

#### What could you expect from this talk?

* What is a container
* Brief introduction about our infrastructure
* Different ways of deploying software
* You need more than just a container

---

What is a container?

![Container](img/containers.jpg)

https://www.flickr.com/photos/sewm/<!-- .element: style="font-size: 50%" -->

---

Simplified: Each container gets its own runtime environment, but all share the same kernel.

---

With the advantage of just running one kernel.

Note:

No additional overhead by VM kernels

---

But the disadvantage of just running one kernel.

---

Same kernel version for all the containers.

---

It is not possible to load different modules for containers.

---

OS type in containers must be the same like the host.

(Which is not true any more!)

---

The most simple way of containering is a traditional chroot environment. Introduced in 1979.

---

Which isolates runtime environments, but does not isolate process space and devices, and does nothing with resource control.

---

In 2000, FreeBSD jails were introduced. chroot was extended further isolation mechanisms, like process namespaces. Processes in one jail can only see processes in the same jail.

Note:

There are more isolations like prohibition of creating device nodes, mounts and so on.

---

In this time, Virtuozzo started with Containers on Linux.

---

My first contact with containers was around 2007

![First Contact](img/first_contact.png)


https://en.wikipedia.org/wiki/Star_Trek:_First_Contact#/media/File:Star_Trek_08-poster.png<!-- .element: style="font-size: 50%" -->

Note:

Containers as in "more than just chroot"

---

When I worked in the Tivoli Storage Manager Team at IBM, where we had to support AIX WPARs and Solaris Zones.

Note:

WPAR = Workload Partition

---

The ideas are still the same, also in the times of Application Containers.

* Using the same kernel.
* Isolate environments as strong as possible.

---

### Why did Containers get this traction in the past few years?

---

I think, it the easy way to create and deploy images.

![Images](img/images.jpg)

https://www.flickr.com/photos/smemon/<!-- .element: style="font-size: 50%" -->

---

We can run the image (almost) everywhere!

Note:

* No matter what: Baremetal, AWS, OpenStack, Google Cloud Engine, you name it.
* Except of our legacy platform tue to technical restrictions.
* In new versions of Virtuozzo this would work fine too.

--

… in a chroot without isolation and resource control using rkt fly by CoreOS

--

… in a small KVM (with an injected kernel), again using rkt, thanks to CoreOS and Intel

--

… on FreeBSD using JetPack

--

… even on Windows!

---

And all this *without* any modification to the image!

---

It changed the way we think about software.

---

### But there will be dragons!

![Dragon](img/dragon.jpg)

--

Unfortunately it is also very easy to build crappy images!!

![Broken](img/broken.jpg)

https://www.flickr.com/photos/57402879@N00/<!-- .element: style="font-size: 50%" -->

--

In my experience, deployments fail more likely because of misconfigured next-hops (like DB), instead of crappy software.

Note:

* Anyway. You now can test it over and over again.

--

Plugging services together is even more difficult in a floating environment.

Note:

* Things like Service Discovery are far out of scope here.

--

More management software is needed!

--

I strongly encourage you to read on this.

* https://charity.wtf/2016/05/31/wtf-is-operations-serverless/<!-- .element: style="font-size: 50%" -->
* https://charity.wtf/2016/05/31/operational-best-practices-serverless/<!-- .element: style="font-size: 50%" -->

--

"Microservices: because solving business problems is hard but building loosely coupled fault-tolerant distributed systems is easy."

https://twitter.com/neil_conway/status/743086761493008384<!-- .element: style="font-size: 50%" -->

---

### So. What are you guys at SysEleven doing?

---

### Running two types of infrastructure!

---

### A new one, based on OpenStack…

![OpenStack](img/Cloud_OpenCloud_Chillin.png)

---

### … an old one, based on Parallels Virtuozzo…

![Virtuozzo](img/virtuozzo.jpg)

Note:

Which basically provides integration into OpenStack these days

---

… but most important: Provide, maintain and monitor the infrastructure into which our customers can deploy their code into.

![Managed](img/managed.png)

Note:

* monitoring as in: doing 24x7 for our customers

---

### On two levels!

---

The hardware and hypervisor "layer".

---

And the running Virtual Environments or Machines.

---

### Let's step into the virtuozzo platform

---

In the past, Virtuozzo was basically

* image format
* local storage
* network isolation
* Linux based container runtime
 * (but maintained outside of mainline)

Note:

around 2008

Which is still true, but there is more

---

… treating containers like usual virtual machines

* with a complete Linux running inside
 * sure, except of the kernel

Note:

Your targeted distribution has to be supported

---

But with a huge performance benefit over VMs

![Performance](img/performance.jpg)

https://www.flickr.com/photos/17612257@N00/<!-- .element: style="font-size: 50%" -->

---

### Some more history

![History](img/history.png)

---

From the early days, we have decent trending and alerting for all the services the customer provides.

Note:

nagios + zabbix for monitoring

---

We even built a web frontend, which gathered data from multiple nagios instances to give us a single overview.

![sNagios](img/nagios.png)

Note:

We run to many things to monitor for a single instance, running on a 24 Core XEON with 94GB RAM

---

Over time, we built billing, a local DNS-API, SSL-Cert "shop", some own metering-endpoints, Backups…

---

… we even developed some tools, to spawn new containers with a minimum set of needed configuration…

![Robot](img/robot.jpg)

---

… with a recommend system to return the best Hardware for the requested container.

![Recommend](img/recommend.jpg)

https://www.flickr.com/photos/jm3/<!-- .element: style="font-size: 50%" -->

---

But we still totally lack a customer facing API.

![Public](img/public.jpg)

---

Everything works via phone and ticketing system.

![Voice activated Admin](img/telefon.jpg)

https://www.flickr.com/photos/nekudo/<!-- .element: style="font-size: 50%" -->

Note:

Voice Activated Admin

Because of this we decided use OpenStack

---

### At some point, Configuration Management became cool

![Puppet](img/puppet.png)

Note:

… and we added a Puppet Master to our infrastructure, and registered all the containers to it. Based on this, we automated much stuff, like provisioning of basic stuff to the container and registering services to the monitoring.

---

But we still treat the containers like computers.

Note:

* more litally

---

![Giraf](img/giraf.jpg)

Note:

* like cute baby girafs

---

### These days we are running

![listvps](img/listvps.png)

Note:

about 3000 of those containers

on about 300 physical machines

---

### A traditional setup is still

* MySQL master slave setup
* Admin server
* a bunch of App server
* maybe some kind of search engine

---

We start the containers, using out internal toolchain.

---

This also triggers puppet to install required software in the container, setting up configuration and register them to our monitoring.

---

We hand over *exactly* this fully managed and running container to the customer.

![Fully managed container](img/managed-container.jpg)
https://www.flickr.com/photos/lindzgraham/<!-- .element: style="font-size: 50%" -->

Note:

Not any kind of image

---

Customers deploy their software to the admin server. From there it will be rsynced to the app server.

![Deploy](img/deploy.jpg)

https://www.flickr.com/photos/auxesis/<!-- .element: style="font-size: 50%" -->

---

All this worked very well for a long period of time!

---

But is very inflexible!

---

Installation of containers is strongly coupled to our infrastructure.

---

So changes to the infra hurt.

---

We have startup dependencies rather than build dependencies.

Note:

Many of them

---

Don't get me wrong!

---

You can build such problems in the shiny new container world as well!

Note:

so take care!

---

Often a new container is just a clone of an old one!

![Clone](img/clone.jpg)

https://www.flickr.com/photos/arenamontanus/<!-- .element: style="font-size: 50%" -->

Note:

With things like host name and monitoring stuff changed

---

There is

![Data](img/data.jpg)

in it.

https://www.flickr.com/photos/trevorandmarjee/<!-- .element: style="font-size: 50%" -->

Note:

At least the entire deployment is not very repeatable.

---

So we keep the containers alive, no matter what happens. In the worst case, we clone one back from the nightly backup.

Note:

Like you might expect. We have to backup the entire container.

---

Updates have to go to all containers…

![Updates](img/updates.jpg)

https://www.flickr.com/photos/bovinity/<!-- .element: style="font-size: 50%" -->

---

… rather than building one new image and replace old containers.

![Replace Container](img/old-container.jpg)

https://www.flickr.com/photos/nicowa/<!-- .element: style="font-size: 50%" -->

Note:

Again, with only build dependencies

---

Because customers software is not packaged in any way…

Note:

It is not easy to verify the installation

---

… there is no overview of the versions of the deployed software.

---

Rollbacks to a defined set of installed software and deployed software are nearly impossible.

![Rollback](img/rollback.jpg)

https://www.flickr.com/photos/thejesse/<!-- .element: style="font-size: 50%" -->

Note:

For sure, everything is possible. Some thing just cause more pain.

Just to name a few

---

Anyway.

This worked fine for a very long time…

---

But these days we need a public facing API

---

We didn't have the man power to develop our own.

---

And we didn't want to build an proprietary

![Island](img/island.jpg)

*again*!

https://www.flickr.com/photos/simuh/<!-- .element: style="font-size: 50%" -->

---

So we came up with OpenStack, and created…

---

![Sys11Stack](img/sys11stack.png)

Note:

Which is an latest OpenStack Mitaka

But changed components for storage and networking

And a bunch of automation to bootstrap

---

We run managed setups in SysEleven Stack.

---

Some customers choose to run production fully managed, and dev on self managed instances.

---

The core concept of running the managed setups is pretty much the same as before.

![Concept](img/concept.jpg)

https://www.flickr.com/photos/yoroy/<!-- .element: style="font-size: 50%" -->

---

But with lessons learned from the old platform!

![Feature](img/feature.jpg)

https://www.flickr.com/photos/pictoquotes/<!-- .element: style="font-size: 50%" -->

---

The setups are flexible, and we can also run them on AWS.

---

It based on ansible, which creates VMs using the specific API, and runs the deployment in it.

---

We train customers to be able to do relevant tasks on their own.

---

In the past half year one question raised…

---

What about

![Docker](img/dacker.jpg)

?

---

Basically you can run every OS you like to. Yet Windows.

---

### So. Yes!

--

Just install docker into the VM.

--

Sure. The containers run in VMs. But IMHO there is *no container vs. VM*, while VMs are one possible infrastructure for containers.

--

Did I mention, that you should keep your infrastructure as boring as possible?

--

Interresting infrastructure tends to fail in interresting ways!

---

Are there future plans to provide managed container services?

--

Yes. But limited to man power!

http://www.syseleven.de/jobs/

--

We yet know what cantainers are. We know the tools and how to debug in the container world.

--

But that is not "managed conatainer services" at all!

---

We think about providing managed orchestration layers.

--

Like

![kubernetes](img/kubernetes.png)

--

… or Docker Swarm

![Docker Swarm](img/swarm.png)

--

We would manage all the services of the conductor.

![Conductor](img/dirigent.jpg)

--

The customer is responsible for the container workloads.

---

FIXME to be gone the rest

---

### What do we all here get from the shiny new world of containers?

---

First of all: Another layer of indirection!


---

Thanks to Docker, it is very very easy to build images! 

---

* Never ever build software in a container that should go to production and leave traces of build utils!
 * Build in a prepared build-container, that only exists to create the artefact.
* You may should build packages for your targeted distribution.
 * Especially if you have dependencies to dist stuff.
* Use Best practices, the tool does not force you to do it right.

Note:

Read on image best practices and why deleting stuff does not reduce the image size!

---

* Never add platform specific stuff like monitoring agents into your container.
* Endpoints for specific monitoring systems are recommended…
* But other services, and a monitoring agent is one, should go into a sidekick container!

---

At this point, you only have build dependencies!

No apt-get/git clone when spawning the container.

Note:

But this is totally up to you.

---

### The real fun starts when your image is created and lives in some registry!

Note:

* No matter if public or private

---

There are ways, like docker-compose or kubectl, to define and run a deployment.

Note:

* So you can test your deployment over and over agan.
* In case of docker-compose they can be set up even locally!
 * or against docker-swarm

---

Really. I dreamed of such things at some points in my IT-life.

---

In the past, I had to deal with deployments to specific hosts, rather than spawning new containers to replace old ones.

Note:

Again. Remember the cute giraf.

---

In any way: Your infrastructure is code as well.

Note:

Which is really good!

---

It is easy to build fresh setups for testing and Q&amp;A.

![ship](img/ship.jpg)

https://www.flickr.com/photos/saifikhan/<!-- .element: style="font-size: 50%" -->

---

Later, the accepted images will be shipped to production.

Unlike installing software on an other (production) computer.

---


You decouple yourself from the exact host, the container is running on.

---

Which definitely does not mean, that you are free of any operational issues.

---

The opposite is true!

---

You have new things running in your infrastructure.

---

Like a new orchestration layer.

---

Or a distributed key/value-Store.

---

Some kind of Service Discovery.

---

You need someone to operate all the new stuff!

---

Debugging apps in containers becomes different.

---

You don't have to throw away your debugging skills!

---

Again the opposite!

---

You have to extend these skills by container debugging!

---

For me, that sounds like creating more operational burden, instead of reducing.

---

### Your applications have to be changed!

---

They have to be "Cloud Ready".

Note:

Bingo

---

Little startup times.

Note:

Otherwise the benefit of not spawning an entire VM does not count.

---

Should be "stateless".

Note:

"global" session stores

There is no lb stickiness!

---

### But

---

You will always have stateful systems.

---

Deal with it.

---

Think about twice or three times.

---

This is the compliacted stuff to deploy!

---

Monitor those services very well!

---

Plan, test and **regulary trigger** failover mechanisms.


---

Whats next on containers at SysEleven?

---

Managed orchestration layer?

---

Like setting up a Kubernetes or Docker Swarm cluster

![Cluster](img/cluster.jpg)

https://www.flickr.com/photos/turkletom/<!-- .element: style="font-size: 50%" -->

---

And monitor and maintain it.

![Monitor](img/monitoring.jpg)

https://www.flickr.com/photos/mray/<!-- .element: style="font-size: 50%" -->

---

But do not care about the services running on it.

---

We could go one step further

---

Running services for customers!

---

Do monitoring and maintenance for the services.

---

Customers could use base images from some official registry and build their own images.

Note:

* Like Docker Hub or quay by CoreOS

---

We could as well provide some base images that we maintain.

---

### But: Here will be some more Dragons

---

What if there is a critical bug in some image?

---

Who is responsible to build a new "production" image?

---

Do we have access to customers code/artefacts to build a new image?

---

Or, do we just notify customers?

---

Who is responsible for rolling out the new image?

Note:

* To recap
* Currently we only update/maintain dist software.
* Do not touch the customers software.

---

### Sounds like even more work for our Admins! Are there any benefits?

---

A very streamlined deployment process!

Note:

No difference between self-deployer

and customers, who only handover their code.

---

In case of Kubernetes: Using Replication Controller.

Note:

Maybe even with auto scaling

Where auto scaling is limited to the running VMs in the kubernetes cluster.

---

Kubernetes takes care about the number of running Pods.

---

No alerts because of a failing frontend node!

---

We are able to run more than one service on a VM, no matter what kind of linux each single service needs.

---

There are separate teams for maintaining the services and running Kubernetes.

---

![Longway](img/longway.jpg)

And not even clear how far to go.

https://www.flickr.com/photos/96665017@N00/<!-- .element: style="font-size: 50%" -->


---

### Is "on OpenStack" the only possible area to use containers at SysEleven?

---

Far away from what is possible!

---

For example, also OpenStack Services are…

---

… Services!

---

Why not maintaining a kubernetes cluster and run OpenStack as a Service?

---

Seriously!

![Stackanetes](img/tectonic-k8s-openstack.svg)

https://tectonic.com/blog/openstack-and-kubernetes-come-together.html

---

### These technologies are around there!

---

They will gain you benefits.

---

But they will introduce new layers of indirection, that you have to manage.

Note:

* or someone for you

---

Not everything fits into a container.

![float problem](img/float_problem.gif)

Note:

* No one forces you to use containers!

---

It will solve all your problems

![Problems](img/all_problems.jpg)

---

# Check the ecosystem

* http://chrigl.de/slides/sysconf15-docker/#/ecosystem<!-- .element: style="font-size: 50%" -->
* http://chrigl.de/slides/sysconf15-docker/#/resources<!-- .element: style="font-size: 50%" -->

Note:

shameless self plugging

---

# And use it!

---

###  But use it wisely!

![Container fail](img/container-accident.jpg)

---

![Good](img/good.jpg)

---

<!-- .slide: class="left" -->

## Thanks! Questions?<!-- .element: style="margin-left:-40px;" -->


![Christoph Glaubitz](../img/Chris.jpg)<!-- .element: style="float:left; margin-left:-40px; margin-right:30px !important;" -->

Contact me:<br>
<i class="fa fa-envelope"></i> [c.glaubitz@syseleven.de](mailto:c.glaubitz@syseleven.de)

Get Awesome Hosting:<br>
[SysEleven.de](http://www.syseleven.de)

</script>
</section>

      </div>
    </div>
	<script src="../reveal.js-3.0.0/lib/js/head.min.js"></script>
	<script src="../reveal.js-3.0.0/js/reveal.js"></script>
	<script>
		// Full list of configuration options available at:
		// https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			history: true,
			center: true,
			slideNumber: false,
			hideAddressBar: true,
			transition: 'slide', // none/fade/slide/convex/concave/zoom
			// Optional reveal.js plugins
			dependencies: [
				{ src: '../reveal.js-3.0.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
				{ src: '../reveal.js-3.0.0/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '../reveal.js-3.0.0/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '../reveal.js-3.0.0/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
				{ src: '../reveal.js-3.0.0/plugin/zoom-js/zoom.js', async: true },
				{ src: '../reveal.js-3.0.0/plugin/notes/notes.js', async: true }
			]
		});
    </script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3595616-6', 'auto');
  ga('send', 'pageview');

</script>
  </body>
</html>
